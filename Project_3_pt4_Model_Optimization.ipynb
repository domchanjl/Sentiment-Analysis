{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model Selection\n",
    "---\n",
    "\n",
    "\n",
    "This notebook contains the code and processes used to assess the effectiveness of potential classification models when used with our pre-processed data, including:\n",
    "\n",
    "- Naive Bayes (Pre-requisite model)\n",
    "    - **The columns of features would be all integer counts, so `MultinomialNB` is the best choice here.**\n",
    "    - BernoulliNB is best when we have 0/1 counts in all columns of X. (a.k.a. dummy variables)\n",
    "    - GaussianNB is best when the columns of X are Normally distributed. \n",
    "    \n",
    "- K-Nearest Neighbors\n",
    "\n",
    "- Logistic Regression Classifier\n",
    "\n",
    "The models are then optimized through an iterative approach. For each model, we have set up a runs DataFrame to store the parameters and results of each GridSearch. The GridSearch is set to a random_state value, so that cross validation selection will be consistent between runs, and we will be able to make direct comparisons over effectiveness of hyperparameters.\n",
    "\n",
    "We start with a wide range for fields of interest, and narrow around the optimally selected value and gauge the degree of accuracy increase (or decrease). Through trial and error, we are able to select hyperparameters that will promote the most accurate modeling results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open cleaned data\n",
    "df_clean = pd.read_csv('./dataset/df_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sw</th>\n",
       "      <th>cleaned_post_stem</th>\n",
       "      <th>cleaned_post_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>new wiki avoid accident encourag suicid spot c...</td>\n",
       "      <td>new wiki avoid accidentally encouraging suicid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>remind absolut activ kind allow day want recog...</td>\n",
       "      <td>reminder absolutely activism kind allowed day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>haha help ye suicid ye get help post mobil bel...</td>\n",
       "      <td>haha help yes suicidal yes getting help posted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>someon pleas talk anyon pleas absolut one turn...</td>\n",
       "      <td>someone please talk anyone please absolutely o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>usual respond post feel like post lot peopl ne...</td>\n",
       "      <td>usually responding post feel like posting lot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sw                                  cleaned_post_stem  \\\n",
       "0      0  new wiki avoid accident encourag suicid spot c...   \n",
       "1      0  remind absolut activ kind allow day want recog...   \n",
       "2      0  haha help ye suicid ye get help post mobil bel...   \n",
       "3      0  someon pleas talk anyon pleas absolut one turn...   \n",
       "4      0  usual respond post feel like post lot peopl ne...   \n",
       "\n",
       "                                    cleaned_post_lem  \n",
       "0  new wiki avoid accidentally encouraging suicid...  \n",
       "1  reminder absolutely activism kind allowed day ...  \n",
       "2  haha help yes suicidal yes getting help posted...  \n",
       "3  someone please talk anyone please absolutely o...  \n",
       "4  usually responding post feel like posting lot ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the X matrix to contain features as both cleaned_post_lem and cleaned_post_stem, and our y target matrix to is_ls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean[['cleaned_post_lem']]\n",
    "y = df_clean['is_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length:1431\n",
      "y_train length:1431\n",
      "X_test length:478\n",
      "y_test length:478\n"
     ]
    }
   ],
   "source": [
    "print('X_train length:{}'.format(len(X_train)))\n",
    "print('y_train length:{}'.format(len(y_train)))\n",
    "print('X_test length:{}'.format(len(X_test)))\n",
    "print('y_test length:{}'.format(len(y_test)))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Model Optimization\n",
    "---\n",
    "\n",
    "### Model selections\n",
    "\n",
    "##### CountVectorizer Multinomial Naive-Bayes (project requirement)\n",
    "\n",
    "- Best Parameters:  {'cvec__max_df': 0.5, 'cvec__max_features': 5000, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 2)}\n",
    "\n",
    "##### CountVectorizer Logistic Regression\n",
    "\n",
    "- Best Parameters:  {'cvec__max_df': 0.5, 'cvec__max_features': 10000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}\n",
    "\n",
    "##### CountVectorizer K-Nearest Neighbors**\n",
    "\n",
    "- Best Parameters:  {'cvec__max_df': 0.2, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the post count vectorized parameter above to furthe optimize the models.  The GridSearch is set to a random_state value, so that cross validation selection will be consistent between runs, and we will be able to make direct comparisons over effectiveness of hyperparameters.\n",
    "\n",
    "We start with a wide range for fields of interest, and narrow around the optimally selected value and gauge the degree of accuracy increase (or decrease). Through trial and error, we are able to select hyperparameters that will promote the most accurate modeling results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### CountVectorizer Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline\n",
    "mnb_params = {\"mnb__alpha\":np.arange(1,1.5,.1), \n",
    "              \"cvec__max_features\":[4000, 5000, 7000, 10000]}\n",
    "\n",
    "# steps defining pipeline sequence and fixed parameters for GridSearch\n",
    "mnb_steps = [('cvec',CountVectorizer(ngram_range= (1, 2))),\n",
    "            ('mnb',MultinomialNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish model pipeline by reference to steps list\n",
    "pipe = Pipeline(mnb_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8714185883997205\n",
      "Test Accuracy:  0.6778242677824268\n",
      "Best Parameters:  {'cvec__max_features': 4000, 'mnb__alpha': 1.2000000000000002}\n",
      "True Negatives: 190\n",
      "False Positives: 56\n",
      "False Negatives: 98\n",
      "True Positives: 134\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# empty dict to store results\n",
    "mnb_post_results = {} \n",
    "\n",
    "# optimize GridSearch hyperparameters on `cv=5` cross validation runs\n",
    "grid = GridSearchCV(pipe, mnb_params, cv=5) \n",
    "# fit to our training data\n",
    "grid.fit(X_train['cleaned_post_lem'], y_train) \n",
    "\n",
    "\n",
    "# print/store training accuracy\n",
    "print('Train Accuracy: ',grid.score(X_train['cleaned_post_lem'], y_train))\n",
    "mnb_post_results['train_accuracy'] = grid.score(X_train['cleaned_post_lem'], y_train) \n",
    "\n",
    "# print/store test accuracy\n",
    "print('Test Accuracy: ',grid.score(X_test['cleaned_post_lem'], y_test))\n",
    "mnb_post_results['test_accuracy'] = grid.score(X_test['cleaned_post_lem'], y_test) \n",
    "\n",
    "# print/store best parameters\n",
    "print('Best Parameters: ',grid.best_params_)\n",
    "mnb_post_results['best_params'] = grid.best_params_ \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test['cleaned_post_lem'])).ravel() # inspect counted results in matrix\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "mnb_post_results['tn'] = tn\n",
    "print(\"False Positives: %s\" % fp)\n",
    "mnb_post_results['fp'] = fp\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "mnb_post_results['fn'] = fn\n",
    "print(\"True Positives: %s\" % tp)\n",
    "mnb_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result Metrics: Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6778242677824268"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy (verification since .score(test) should get the same result)\n",
    "(mnb_post_results['tn'] + mnb_post_results['tp']) / (mnb_post_results['tn'] + mnb_post_results['fp'] + mnb_post_results['fn'] + mnb_post_results['tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5775862068965517"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "mnb_post_results['tp'] / (mnb_post_results['tp'] + mnb_post_results['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7723577235772358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "mnb_post_results['tn'] / (mnb_post_results['tn'] + mnb_post_results['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7052631578947368"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "mnb_post_results['tp'] / (mnb_post_results['tp'] + mnb_post_results['fp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### CountVectorizer Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline\n",
    "lr_params = {\"lr__penalty\":['l1', 'l2'], \n",
    "             \"lr__C\": np.arange(1,1.5,.1),\n",
    "             \"lr__tol\":[.00035],\n",
    "             \"cvec__max_features\":[5000,10000,20000,30000]}\n",
    "lr_steps = [('cvec',CountVectorizer(ngram_range= (1, 2))),\n",
    "            ('lr',LogisticRegression(random_state=42))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish model pipeline by reference to steps list\n",
    "pipe = Pipeline(lr_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9937106918238994\n",
      "Test Accuracy:  0.6924686192468619\n",
      "Best Parameters:  {'cvec__max_features': 30000, 'lr__C': 1.0, 'lr__penalty': 'l2', 'lr__tol': 0.00035}\n",
      "True Negatives: 187\n",
      "False Positives: 59\n",
      "False Negatives: 88\n",
      "True Positives: 144\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# empty dict to store results\n",
    "lr_post_results = {}\n",
    "\n",
    "# optimize GridSearch hyperparameters on `cv=5` cross validation runs\n",
    "grid = GridSearchCV(pipe, lr_params, cv=5)\n",
    "# fit to our training data\n",
    "grid.fit(X_train['cleaned_post_lem'], y_train)\n",
    "\n",
    "# print/store training accuracy\n",
    "print('Train Accuracy: ',grid.score(X_train['cleaned_post_lem'], y_train))\n",
    "lr_post_results['train_accuracy'] = grid.score(X_train['cleaned_post_lem'], y_train)\n",
    "\n",
    "# print/store test accuracy\n",
    "print('Test Accuracy: ',grid.score(X_test['cleaned_post_lem'], y_test))\n",
    "lr_post_results['test_accuracy'] = grid.score(X_test['cleaned_post_lem'], y_test)\n",
    "\n",
    "# print/store best parameters\n",
    "print('Best Parameters: ',grid.best_params_)\n",
    "lr_post_results['bp'] = grid.best_params_\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test['cleaned_post_lem'])).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "lr_post_results['tn'] = tn\n",
    "print(\"False Positives: %s\" % fp)\n",
    "lr_post_results['fp'] = fp\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "lr_post_results['fn'] = fn\n",
    "print(\"True Positives: %s\" % tp)\n",
    "lr_post_results['tp'] = tp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result Metrics: CountVectorized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6924686192468619"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy (verification since .score(test) should get the same result)\n",
    "(lr_post_results['tn'] + lr_post_results['tp']) / (lr_post_results['tn'] + lr_post_results['fp'] + lr_post_results['fn'] + lr_post_results['tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6206896551724138"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "lr_post_results['tp'] / (lr_post_results['tp'] + lr_post_results['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7601626016260162"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "lr_post_results['tn'] / (lr_post_results['tn'] + lr_post_results['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7093596059113301"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "lr_post_results['tp'] / (lr_post_results['tp'] + lr_post_results['fp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### CountVectorizer K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline\n",
    "knn_params = {\"knn__n_neighbors\":np.arange(4,20,2),\n",
    "              \"cvec__max_features\":[500, 1000, 3000]}\n",
    "\n",
    "# steps defining pipeline sequence and fixed parameters for GridSearch\n",
    "knn_steps = [('cvec',CountVectorizer(ngram_range= (1, 2))),\n",
    "            ('knn',KNeighborsClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish model pipeline by reference to steps list\n",
    "pipe = Pipeline(knn_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6373165618448637\n",
      "Test Accuracy:  0.606694560669456\n",
      "Best Parameters:  {'cvec__max_features': 500, 'knn__n_neighbors': 12}\n",
      "True Negatives: 215\n",
      "False Positives: 31\n",
      "False Negatives: 157\n",
      "True Positives: 75\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# empty dict to store results\n",
    "knn_post_results = {} \n",
    "\n",
    "# optimize GridSearch hyperparameters on `cv=5` cross validation runs\n",
    "grid = GridSearchCV(pipe, knn_params, cv=5) \n",
    "# fit to our training data\n",
    "grid.fit(X_train['cleaned_post_lem'], y_train) \n",
    "\n",
    "\n",
    "# print/store training accuracy\n",
    "print('Train Accuracy: ',grid.score(X_train['cleaned_post_lem'], y_train))\n",
    "knn_post_results['train_accuracy'] = grid.score(X_train['cleaned_post_lem'], y_train) \n",
    "\n",
    "# print/store test accuracy\n",
    "print('Test Accuracy: ',grid.score(X_test['cleaned_post_lem'], y_test))\n",
    "knn_post_results['test_accuracy'] = grid.score(X_test['cleaned_post_lem'], y_test) \n",
    "\n",
    "# print/store best parameters\n",
    "print('Best Parameters: ',grid.best_params_)\n",
    "knn_post_results['best_params'] = grid.best_params_ \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test['cleaned_post_lem'])).ravel() # inspect counted results in matrix\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "knn_post_results['tn'] = tn\n",
    "print(\"False Positives: %s\" % fp)\n",
    "knn_post_results['fp'] = fp\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "knn_post_results['fn'] = fn\n",
    "print(\"True Positives: %s\" % tp)\n",
    "knn_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result Metrics: CountVectorized KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606694560669456"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy (verification since .score(test) should get the same result)\n",
    "(knn_post_results['tn'] + knn_post_results['tp']) / (knn_post_results['tn'] + knn_post_results['fp'] + knn_post_results['fn'] + knn_post_results['tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3232758620689655"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "knn_post_results['tp'] / (knn_post_results['tp'] + knn_post_results['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8739837398373984"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "knn_post_results['tn'] / (knn_post_results['tn'] + knn_post_results['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7075471698113207"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "knn_post_results['tp'] / (knn_post_results['tp'] + knn_post_results['fp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized features\n",
    "\n",
    "##### Model 1: Multinomial Naive-Bayes\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - ngram_range=(1,2)\n",
    "- GridSearch\n",
    "    - cv__max_features=4000\n",
    "    - mnb__alpha=1.2\n",
    "- Train Accuracy:  0.8714185883997205\n",
    "- Test Accuracy:  0.6778242677824268\n",
    "\n",
    "\n",
    "##### Model 2: Logistic Regression\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - ngram_range=(1,2)\n",
    "- GridSearch\n",
    "    - cv__max_features=30000\n",
    "    - lr__penalty='l2'\n",
    "    - lr__C=1\n",
    "    - lr__tol=.000035\n",
    "- Train Accuracy:  0.9937106918238994\n",
    "- Test Accuracy:  0.6924686192468619\n",
    "\n",
    "\n",
    "##### Model 3: K-Nearest Neighbors\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - ngram_range=(1,2)\n",
    "- GridSearch\n",
    "    - cv__max_features=500\n",
    "    - knn_n_neighbors=12\n",
    "- Train Accuracy:  0.6373165618448637\n",
    "- Test Accuracy:  0.606694560669456\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy scores for Logistic Regression model was better than K-Nearest Neighbor model, although both were improved with tuning of hyperparameters. Multinomial Naive Bayes, however, saw a decrease in test scores.\n",
    "\n",
    "Highest-performing model is Logistic Regression, and coefficients allow us to understand the data easily. Moreover, we see improvements to the metrics of accuracy, specificity, sensitivity and precision. Despite tuning the parameters, I could not get better than 69.2% accuracy, unfortunately.\n",
    "\n",
    "I spent some time trying to generalize pipelines in order to efficiently run lots of different grid searches on many different models and parameters. This generalized function has room for improvement, but was quite helpful for me to stay organized in my tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
