{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Text Feature Selection\n",
    "---\n",
    "\n",
    "This notebook contains the code and processes used to assess the effectiveness of text feature selection models when used with the pre-processed data. Using the columns of lemmatized words, the two vectorization transformers, CountVectorizer and TF-IDF, are modelled using\n",
    "- Naive Bayes\n",
    "- K-Nearest Neighbors\n",
    "- Logistic Regression Classifier\n",
    "\n",
    "A GridSearch is run across all models to rule out non-viable options. The text feature selection that give the models with the most predictive potential are then selected and optimized in the next notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open cleaned data\n",
    "df_clean = pd.read_csv('./dataset/df_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sw</th>\n",
       "      <th>cleaned_post_stem</th>\n",
       "      <th>cleaned_post_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>new wiki avoid accident encourag suicid spot c...</td>\n",
       "      <td>new wiki avoid accidentally encouraging suicid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>remind absolut activ kind allow day want recog...</td>\n",
       "      <td>reminder absolutely activism kind allowed day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>haha help ye suicid ye get help post mobil bel...</td>\n",
       "      <td>haha help yes suicidal yes getting help posted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>someon pleas talk anyon pleas absolut one turn...</td>\n",
       "      <td>someone please talk anyone please absolutely o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>usual respond post feel like post lot peopl ne...</td>\n",
       "      <td>usually responding post feel like posting lot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sw                                  cleaned_post_stem  \\\n",
       "0      0  new wiki avoid accident encourag suicid spot c...   \n",
       "1      0  remind absolut activ kind allow day want recog...   \n",
       "2      0  haha help ye suicid ye get help post mobil bel...   \n",
       "3      0  someon pleas talk anyon pleas absolut one turn...   \n",
       "4      0  usual respond post feel like post lot peopl ne...   \n",
       "\n",
       "                                    cleaned_post_lem  \n",
       "0  new wiki avoid accidentally encouraging suicid...  \n",
       "1  reminder absolutely activism kind allowed day ...  \n",
       "2  haha help yes suicidal yes getting help posted...  \n",
       "3  someone please talk anyone please absolutely o...  \n",
       "4  usually responding post feel like posting lot ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the X matrix to contain features as both cleaned_post_lem and cleaned_post_stem, and our y target matrix to is_ls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean[['cleaned_post_lem']]\n",
    "y = df_clean['is_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length:1431\n",
      "y_train length:1431\n",
      "X_test length:478\n",
      "y_test length:478\n"
     ]
    }
   ],
   "source": [
    "print('X_train length:{}'.format(len(X_train)))\n",
    "print('y_train length:{}'.format(len(y_train)))\n",
    "print('X_test length:{}'.format(len(X_test)))\n",
    "print('y_test length:{}'.format(len(y_test)))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Text Feature Extraction Comparison by means of Modelling\n",
    "\n",
    "As the feature words are still unstructured for analysis, employ count vectorization and TF-IDF to transform the lists of the cleaned reviews above into features passable into a model.\n",
    "\n",
    "- It will create columns (also knon as vectors), where each column counts how many times each word is observed in each review.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Count Vectorizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of steps in pipeline model for each classifier model\n",
    "steps_list_gr_cvec = [\n",
    "    [('cvec',CountVectorizer()),('multi_nb',MultinomialNB())],\n",
    "    [('cvec',CountVectorizer()),('scaler',StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())], \n",
    "    [('cvec',CountVectorizer()),('scaler',StandardScaler(with_mean=False)),('logreg',LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','knn','logreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for models\n",
    "pipe_params_cvec = [\n",
    "    {\"cvec__ngram_range\":[(1,1),(1,2)], 'cvec__max_features': [1000, 5000, 10000], 'cvec__min_df': [2, 3], 'cvec__max_df': [.2, 0.25, .5, .8],},\n",
    "    {\"cvec__ngram_range\":[(1,1),(1,2)], 'cvec__max_features': [1000, 5000, 10000], 'cvec__min_df': [2, 3], 'cvec__max_df': [.2, 0.25, .5, .8],},\n",
    "    {\"cvec__ngram_range\":[(1,1),(1,2)], 'cvec__max_features': [1000, 5000, 10000], 'cvec__min_df': [2, 3], 'cvec__max_df': [.2, 0.25, .5, .8],}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, tn, fp, fn, tp]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create results DataFrame\n",
    "grid_results_cvec = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','tn','fp','fn','tp'])\n",
    "grid_results_cvec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb\n",
      "Best Params:  {'cvec__max_df': 0.5, 'cvec__max_features': 5000, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 2)}\n",
      "0.8909853249475891 \n",
      "\n",
      "0.698744769874477 \n",
      "\n",
      "True Negatives: 193\n",
      "False Positives: 53\n",
      "False Negatives: 91\n",
      "True Positives: 141 \n",
      "\n",
      "Model:  knn\n",
      "Best Params:  {'cvec__max_df': 0.2, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}\n",
      "0.6638714185883997 \n",
      "\n",
      "0.5857740585774058 \n",
      "\n",
      "True Negatives: 232\n",
      "False Positives: 14\n",
      "False Negatives: 184\n",
      "True Positives: 48 \n",
      "\n",
      "Model:  logreg\n",
      "Best Params:  {'cvec__max_df': 0.5, 'cvec__max_features': 10000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}\n",
      "0.9958071278825996 \n",
      "\n",
      "0.6234309623430963 \n",
      "\n",
      "True Negatives: 170\n",
      "False Positives: 76\n",
      "False Negatives: 104\n",
      "True Positives: 128 \n",
      "\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(steps_list_gr_cvec)):                 \n",
    "    pipe = Pipeline(steps=steps_list_gr_cvec[i])         # configure pipeline for each model\n",
    "    grid = GridSearchCV(pipe, pipe_params_cvec[i], cv=5) # fit GridSearchCV to model and model's params\n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    grid.fit(X_train['cleaned_post_lem'], y_train)\n",
    "    \n",
    "    print('Model: ',steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', grid.best_params_)\n",
    "    model_results['best_params'] = grid.best_params_\n",
    "\n",
    "    print(grid.score(X_train['cleaned_post_lem'], y_train), '\\n')\n",
    "    model_results['train_accuracy'] = grid.score(X_train['cleaned_post_lem'], y_train)\n",
    "    \n",
    "    print(grid.score(X_test['cleaned_post_lem'], y_test), '\\n')\n",
    "    model_results['test_accuracy'] = grid.score(X_test['cleaned_post_lem'], y_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test['cleaned_post_lem'])).ravel()\n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    model_results['tn'] = tn\n",
    "\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    model_results['fp'] = fp\n",
    "\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    model_results['fn'] = fn\n",
    "\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    model_results['tp'] = tp\n",
    "\n",
    "    grid_results_cvec = grid_results_cvec.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "- Common words are penalized.\n",
    "- Rare words have more influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of steps in pipeline model for each classifier model\n",
    "steps_list_gr_tvec = [\n",
    "    [('tvec',TfidfVectorizer()),('multi_nb',MultinomialNB())],\n",
    "    [('tvec',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())], \n",
    "    [('tvec',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('logreg',LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','knn','logreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for models\n",
    "pipe_params_tvec = [\n",
    "    {\"tvec__ngram_range\":[(1,1),(1,2)], 'tvec__max_features': [1000, 5000, 10000], 'tvec__min_df': [2, 3], 'tvec__max_df': [.2, 0.25, .5, .8],},\n",
    "    {\"tvec__ngram_range\":[(1,1),(1,2)], 'tvec__max_features': [1000, 5000, 10000], 'tvec__min_df': [2, 3], 'tvec__max_df': [.2, 0.25, .5, .8],},\n",
    "    {\"tvec__ngram_range\":[(1,1),(1,2)], 'tvec__max_features': [1000, 5000, 10000], 'tvec__min_df': [2, 3], 'tvec__max_df': [.2, 0.25, .5, .8],}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, tn, fp, fn, tp]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create results DataFrame\n",
    "grid_results_tvec = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','tn','fp','fn','tp'])\n",
    "grid_results_tvec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb\n",
      "Best Params:  {'tvec__max_df': 0.5, 'tvec__max_features': 1000, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1)}\n",
      "0.8301886792452831 \n",
      "\n",
      "0.6924686192468619 \n",
      "\n",
      "True Negatives: 197\n",
      "False Positives: 49\n",
      "False Negatives: 98\n",
      "True Positives: 134 \n",
      "\n",
      "Model:  knn\n",
      "Best Params:  {'tvec__max_df': 0.25, 'tvec__max_features': 1000, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 2)}\n",
      "0.6198462613556953 \n",
      "\n",
      "0.5376569037656904 \n",
      "\n",
      "True Negatives: 238\n",
      "False Positives: 8\n",
      "False Negatives: 213\n",
      "True Positives: 19 \n",
      "\n",
      "Model:  logreg\n",
      "Best Params:  {'tvec__max_df': 0.2, 'tvec__max_features': 5000, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2)}\n",
      "0.9944095038434662 \n",
      "\n",
      "0.6485355648535565 \n",
      "\n",
      "True Negatives: 169\n",
      "False Positives: 77\n",
      "False Negatives: 91\n",
      "True Positives: 141 \n",
      "\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(steps_list_gr_tvec)):                 \n",
    "    pipe = Pipeline(steps=steps_list_gr_tvec[i])         # configure pipeline for each model\n",
    "    grid = GridSearchCV(pipe, pipe_params_tvec[i], cv=5) # fit GridSearchCV to model and model's params\n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    grid.fit(X_train['cleaned_post_lem'], y_train)\n",
    "    \n",
    "    print('Model: ',steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', grid.best_params_)\n",
    "    model_results['best_params'] = grid.best_params_\n",
    "\n",
    "    print(grid.score(X_train['cleaned_post_lem'], y_train), '\\n')\n",
    "    model_results['train_accuracy'] = grid.score(X_train['cleaned_post_lem'], y_train)\n",
    "    \n",
    "    print(grid.score(X_test['cleaned_post_lem'], y_test), '\\n')\n",
    "    model_results['test_accuracy'] = grid.score(X_test['cleaned_post_lem'], y_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test['cleaned_post_lem'])).ravel()\n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    model_results['tn'] = tn\n",
    "\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    model_results['fp'] = fp\n",
    "\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    model_results['fn'] = fn\n",
    "\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    model_results['tp'] = tp\n",
    "\n",
    "    grid_results_tvec = grid_results_tvec.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 2. Results assessment\n",
    "\n",
    "Add columns measuring the difference of accuracy scores between training and test set, and test set and baseline accuracy. This will tell us about the level of overfitting that may be present in each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.514929\n",
       "1    0.485071\n",
       "Name: is_sw, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify majority as baseline accuracy\n",
    "df_clean['is_sw'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy is the likelihood of a post being is_sw=1 based solely on the percentage of the dataset that is the target value. Normalizing the value counts, and identify majority group and take that as the baseline accuracy of 51.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity\n",
    "grid_results_tvec['specificity'] = grid_results_tvec['tn'] / (grid_results_tvec['tn']+grid_results_tvec['fp'])\n",
    "grid_results_cvec['specificity'] = grid_results_cvec['tn'] / (grid_results_cvec['tn']+grid_results_cvec['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positive rate\n",
    "grid_results_tvec['fpr'] = grid_results_tvec['fp'] / (grid_results_tvec['tn']+grid_results_tvec['fp'])\n",
    "grid_results_cvec['fpr'] = grid_results_cvec['fp'] / (grid_results_cvec['tn']+grid_results_cvec['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference of accuracy scores between training and test set = tt_diff\n",
    "grid_results_tvec['tt_diff'] = grid_results_tvec['train_accuracy'] - grid_results_tvec['test_accuracy']\n",
    "grid_results_cvec['tt_diff'] = grid_results_cvec['train_accuracy'] - grid_results_cvec['test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline accuracy = ba_diff\n",
    "grid_results_tvec['bl_diff'] =  grid_results_tvec['test_accuracy'] - df_clean['is_sw'].value_counts(normalize=True)[0]\n",
    "grid_results_cvec['bl_diff'] =  grid_results_cvec['test_accuracy'] - df_clean['is_sw'].value_counts(normalize=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tt_diff</th>\n",
       "      <th>bl_diff</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 50...</td>\n",
       "      <td>0.890985</td>\n",
       "      <td>0.698745</td>\n",
       "      <td>193</td>\n",
       "      <td>53</td>\n",
       "      <td>91</td>\n",
       "      <td>141</td>\n",
       "      <td>0.215447</td>\n",
       "      <td>0.192241</td>\n",
       "      <td>0.183815</td>\n",
       "      <td>0.784553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'cvec__max_df': 0.5, 'cvec__max_features': 10...</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>0.623431</td>\n",
       "      <td>170</td>\n",
       "      <td>76</td>\n",
       "      <td>104</td>\n",
       "      <td>128</td>\n",
       "      <td>0.308943</td>\n",
       "      <td>0.372376</td>\n",
       "      <td>0.108502</td>\n",
       "      <td>0.691057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'cvec__max_df': 0.2, 'cvec__max_features': 10...</td>\n",
       "      <td>0.663871</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>232</td>\n",
       "      <td>14</td>\n",
       "      <td>184</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0569106</td>\n",
       "      <td>0.078097</td>\n",
       "      <td>0.070845</td>\n",
       "      <td>0.943089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "0  multi_nb  {'cvec__max_df': 0.5, 'cvec__max_features': 50...   \n",
       "2    logreg  {'cvec__max_df': 0.5, 'cvec__max_features': 10...   \n",
       "1       knn  {'cvec__max_df': 0.2, 'cvec__max_features': 10...   \n",
       "\n",
       "   train_accuracy  test_accuracy   tn  fp   fn   tp        fpr   tt_diff  \\\n",
       "0        0.890985       0.698745  193  53   91  141   0.215447  0.192241   \n",
       "2        0.995807       0.623431  170  76  104  128   0.308943  0.372376   \n",
       "1        0.663871       0.585774  232  14  184   48  0.0569106  0.078097   \n",
       "\n",
       "    bl_diff specificity  \n",
       "0  0.183815    0.784553  \n",
       "2  0.108502    0.691057  \n",
       "1  0.070845    0.943089  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show grid results for CountVect models\n",
    "grid_results_cvec.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tt_diff</th>\n",
       "      <th>bl_diff</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'tvec__max_df': 0.5, 'tvec__max_features': 10...</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.692469</td>\n",
       "      <td>197</td>\n",
       "      <td>49</td>\n",
       "      <td>98</td>\n",
       "      <td>134</td>\n",
       "      <td>0.199187</td>\n",
       "      <td>0.137720</td>\n",
       "      <td>0.177539</td>\n",
       "      <td>0.800813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'tvec__max_df': 0.2, 'tvec__max_features': 50...</td>\n",
       "      <td>0.994410</td>\n",
       "      <td>0.648536</td>\n",
       "      <td>169</td>\n",
       "      <td>77</td>\n",
       "      <td>91</td>\n",
       "      <td>141</td>\n",
       "      <td>0.313008</td>\n",
       "      <td>0.345874</td>\n",
       "      <td>0.133606</td>\n",
       "      <td>0.686992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'tvec__max_df': 0.25, 'tvec__max_features': 1...</td>\n",
       "      <td>0.619846</td>\n",
       "      <td>0.537657</td>\n",
       "      <td>238</td>\n",
       "      <td>8</td>\n",
       "      <td>213</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0325203</td>\n",
       "      <td>0.082189</td>\n",
       "      <td>0.022728</td>\n",
       "      <td>0.96748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "0  multi_nb  {'tvec__max_df': 0.5, 'tvec__max_features': 10...   \n",
       "2    logreg  {'tvec__max_df': 0.2, 'tvec__max_features': 50...   \n",
       "1       knn  {'tvec__max_df': 0.25, 'tvec__max_features': 1...   \n",
       "\n",
       "   train_accuracy  test_accuracy   tn  fp   fn   tp        fpr   tt_diff  \\\n",
       "0        0.830189       0.692469  197  49   98  134   0.199187  0.137720   \n",
       "2        0.994410       0.648536  169  77   91  141   0.313008  0.345874   \n",
       "1        0.619846       0.537657  238   8  213   19  0.0325203  0.082189   \n",
       "\n",
       "    bl_diff specificity  \n",
       "0  0.177539    0.800813  \n",
       "2  0.133606    0.686992  \n",
       "1  0.022728     0.96748  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show grid results for tf-idf models\n",
    "grid_results_tvec.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observed that CountVectorized and TF-IDF models performed relatively similarly. We assess which models will be the best to optimize by consolidating and sorting the results values by test_accuracy. Additionally, two of the three models using cvec feature selection tools are registered lower false negatives. False negatives are posts wrongly predicted to be in the \"Depression\" subreddit instead of \"SuicideWatch\". Before tuning, it is less of a concern but we should take note of that for model tuning and optimization. (The false negative rate is also 1-specificity)\n",
    "\n",
    "**Since CountVectorized models registered the highest scores for accuracy, we will use that as our vectorizer.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
